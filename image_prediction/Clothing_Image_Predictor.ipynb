{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model to identify different types of clothing.  To make models that train quickly, very small (low-resolution) images are used. The model will take images like this and identify it as a shoe:\n",
    "\n",
    "![Imgur](https://i.imgur.com/GyXOnSB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is used to identify clothing types in the **MNIST for Fashion** dataset. Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n",
    "\n",
    "- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "0. T-shirt/top\n",
    "1. Trouser\n",
    "2. Pullover\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 32s 668us/sample - loss: 0.4200 - acc: 0.8500 - val_loss: 0.3380 - val_acc: 0.8800\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 33s 687us/sample - loss: 0.2809 - acc: 0.8961 - val_loss: 0.2841 - val_acc: 0.8988\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 33s 685us/sample - loss: 0.2257 - acc: 0.9153 - val_loss: 0.2661 - val_acc: 0.9028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2900129fbe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "#Preprocess the data to use DL model\n",
    "batch_size = 16\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    y = raw[:, 0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    x = raw[:,1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "fashion_file = \"C:\\\\Users\\Divyaprakash\\Downloads\\\\fashionmnist\\\\fashion-mnist_train.csv\"\n",
    "fashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\n",
    "x, y = prep_data(fashion_data)\n",
    "\n",
    "#Build the model.(sequential convolution2d)\n",
    "fashion_model_1 = Sequential()\n",
    "fashion_model_1.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "fashion_model_1.add(Conv2D(16, (3, 3), activation='relu', strides=2))\n",
    "fashion_model_1.add(Flatten())\n",
    "fashion_model_1.add(Dense(128, activation='relu'))\n",
    "fashion_model_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Complile the model\n",
    "fashion_model_1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Fit and train model\n",
    "fashion_model_1.fit(x, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
